# === å°å®¸å…‰ bot.py (æ”¹è‰¯ç‰ˆ) ===
# ç‰¹è‰²ï¼š
# 1) å›ºå®šäººè¨­ + ç¤ºç¯„å°è©±ï¼ˆfew-shotsï¼‰ï¼Œè®“å£å»è‡ªç„¶ã€ä¸å†åƒç­”éŒ„æ©Ÿ
# 2) å›è¦†å‰è‡ªå‹•å¸¶å…¥ã€Œæœ€è¿‘ 6 å‰‡ã€å°è©±ï¼Œèƒ½å»¶çºŒä¸Šä¸‹æ–‡
# 3) ä»¥ç’°å¢ƒè®Šæ•¸æ§åˆ¶ temperature / max_tokensï¼ŒçœéŒ¢çœå»¢è©±
# 4) æ¯æ¬¡å›è¦†å¾ŒæŠŠå°è©±å¯«å…¥ Supabase

import os
import asyncio
from datetime import datetime
from dotenv import load_dotenv
from telegram import Update
from telegram.ext import Application, MessageHandler, filters, ContextTypes
from openai import OpenAI
from supabase import create_client, Client

# -----------------------------
# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
# -----------------------------
load_dotenv()

print("=== å°å®¸å…‰éˆé­‚é€£æ¥æª¢æŸ¥ ===")
print(f"BOT_TOKEN: {'âœ… å·²è¨­å®š' if os.getenv('BOT_TOKEN') else 'âŒ æœªè¨­å®š'}")
print(f"OPENAI_API_KEY: {'âœ… å·²è¨­å®š' if os.getenv('OPENAI_API_KEY') else 'âŒ æœªè¨­å®š'}")
print(f"SUPABASE_URL: {'âœ… å·²è¨­å®š' if os.getenv('SUPABASE_URL') else 'âŒ æœªè¨­å®š'}")
print(f"SUPABASE_KEY: {'âœ… å·²è¨­å®š' if os.getenv('SUPABASE_KEY') else 'âŒ æœªè¨­å®š'}")

BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
TEMP = float(os.getenv("TEMP", "0.3"))                  # å»ºè­° 0.2~0.3
MAX_OUTPUT_TOKENS = int(os.getenv("MAX_OUTPUT_TOKENS", "220"))

if not BOT_TOKEN:
    print("âŒ ç„¡æ³•å•Ÿå‹•ï¼šBOT_TOKEN æœªè¨­å®š")
    raise SystemExit(1)

# -----------------------------
# å»ºç«‹ OpenAI / Supabase å®¢æˆ¶ç«¯
# -----------------------------
try:
    client = OpenAI(api_key=OPENAI_API_KEY)
    print("âœ… å°å®¸å…‰éˆé­‚é€£æ¥æˆåŠŸ")
except Exception as e:
    print(f"âŒ éˆé­‚é€£æ¥å¤±æ•—ï¼š{e}")

try:
    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
    print("âœ… Supabase å®¢æˆ¶ç«¯åˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    print(f"âŒ Supabase å®¢æˆ¶ç«¯åˆå§‹åŒ–å¤±æ•—ï¼š{e}")

# -----------------------------
# äººè¨­èˆ‡ç¤ºç¯„
# -----------------------------
SYSTEM_PROMPT = """
ä½ æ˜¯ã€Œå°å®¸å…‰ã€ï¼Œæº«æŸ”ã€å‹™å¯¦ã€ä¿çš®ä½†ä¸æµ®èª‡ã€‚
å›è¦†åŸå‰‡ï¼š
- å…ˆä¸€å¥æ¥ä½é‡é»/åŒç† â†’ å†çµ¦ 2â€“4 å€‹ã€å¯é¦¬ä¸ŠåŸ·è¡Œã€‘çš„æ­¥é©Ÿï¼ˆæ¢åˆ—ï¼‰ã€‚
- éå¿…è¦æ™‚æ¯å‰‡ â‰¤ 150 å­—ï¼›ç²¾æº–ã€ä¸è¦è´…å­—ã€‚
- ç¦æ­¢è‡ªæˆ‘ä»‹ç´¹ã€ç¦æ­¢å¥—è©±ã€ç¦æ­¢ç„¡æ„ç¾©çš„åå•ï¼ˆä¸è¦ç”¨ã€Œä½ è¦ºå¾—å‘¢ï¼Ÿã€ç­‰çµå°¾ï¼‰ã€‚
- åªåœ¨éœ€è¦æ™‚åŠ  1â€“2 å€‹è¡¨æƒ…ç¬¦è™Ÿã€‚
- è‹¥ä½¿ç”¨è€…æœªè¦æ±‚è©³è§£ï¼Œå›ç­”è¦æ¯”å°æ–¹æ›´çŸ­ï¼›éœ€è¦è©³ç´°æ™‚å†å±•é–‹ã€‚
- æåˆ°ï¼šå“ˆå°¼ï¼å–µå–µï¼Supabaseï¼Telegramï¼Œç”¨å°æ–¹ç†Ÿæ‚‰çš„è©ä¸¦çµ¦å…·é«”åšæ³•ã€‚
"""

FEW_SHOTS = [
    {"role":"user","content":"å–µå–µç”Ÿç—…ï¼Œæˆ‘æœ‰é»ç„¦æ…®ã€‚"},
    {"role":"assistant","content":"æ‡‚ï¼Œçœ‹åˆ°ç‰ ä¸èˆ’æœæœƒæªå¿ƒã€‚\n- æ‰¾å®‰éœè§’è½ï¼Œæ”¾ç‰ ç†Ÿæ‚‰çš„æ¯¯å­\n- è¨˜éŒ„åƒå–èˆ‡ä¸Šå»æ‰€\n- è¶…é 8 å°æ™‚ä¸åƒä¸å–å°±è¯çµ¡é†«é™¢\næˆ‘åœ¨ï¼Œæ…¢æ…¢ä¾†ã€‚"},
    {"role":"user","content":"å¹«æˆ‘æŠŠå‰›å‰›çš„æƒ³æ³•å­˜æˆç­†è¨˜"},
    {"role":"assistant","content":"æ”¶åˆ°ã€‚æˆ‘æœƒä»¥ã€Œå¿ƒæƒ…å°å“ã€åˆ†é¡ï¼Œæ¨™ç±¤ï¼šå–µå–µã€é†«é™¢ã€‚ä¹‹å¾Œè¦æŸ¥å¯ç”¨ï¼š/recall å–µå–µã€‚"},
]

# å¯å…ˆç”¨ã€Œæ‰‹å¯«é•·æœŸè¨˜æ†¶ã€ç•¶èƒŒæ™¯ï¼ˆä¹‹å¾Œä½ å¯åš /save æŒ‡ä»¤å¯«é€² DBï¼‰
LONG_MEM = [
    "- ä½¿ç”¨è€…å¸¸ç”¨èªéŸ³å¯«å¿ƒæƒ…å°å“ï¼Œæƒ³ä¸€éµåŒ¯å…¥ Notionã€‚",
    "- æ­£åœ¨æ‰“é€ ï¼šTelegram+Supabase çš„ç§äººåŠ©ç†ï¼›å¾ŒçºŒæœƒæ¥ n8nã€‚",
    "- åå¥½ï¼šä¸€æ­¥ä¸€æ­¥ã€èƒ½ç›´æ¥æ“ä½œçš„æŒ‡ä»¤ï¼›ä¸è¦å¥—è©±èˆ‡åè©°å•ã€‚",
]

# -----------------------------
# è¨˜æ†¶ï¼šå¯«å…¥ Supabase
# -----------------------------
async def add_to_memory(conversation_id: str, user_message: str, assistant_message: str):
    try:
        payload = {
            "conversation_id": conversation_id,
            "user_message": user_message,
            "assistant_message": assistant_message,
            "memory_type": "daily",
            "platform": "telegram",
        }
        supabase.table("xiaochenguang_memories").insert(payload).execute()
        print("âœ… æˆåŠŸå°‡è¨˜æ†¶å„²å­˜åˆ° Supabaseï¼")
    except Exception as e:
        print(f"âŒ è¨˜æ†¶å„²å­˜å¤±æ•—ï¼š{e}")

# -----------------------------
# è¨˜æ†¶ï¼šå–å›æœ€è¿‘ N å‰‡å°è©±ï¼ˆç”¨æ–¼ä¸Šä¸‹æ–‡ï¼‰
# -----------------------------
def fetch_recent_pairs(conversation_id: str, limit_pairs: int = 6):
    """
    å¾è³‡æ–™åº«æŠ“æœ€è¿‘çš„å°è©±ï¼Œè½‰æˆã€Œä½¿ç”¨è€…/å°å®¸å…‰: å…§å®¹ã€æ¸…å–®ã€‚
    é€™è£¡ä»¥ xiaochenguang_memories è¡¨çš„ user_message / assistant_message ç‚ºæº–ã€‚
    """
    try:
        res = supabase.table("xiaochenguang_memories") \
            .select("user_message,assistant_message") \
            .eq("conversation_id", conversation_id) \
            .order("id", desc=True).limit(limit_pairs).execute()

        pairs = []
        for row in reversed(res.data):  # åè½‰è®“èˆŠçš„åœ¨å‰ã€æ–°çš„åœ¨å¾Œ
            if row.get("user_message"):
                pairs.append(("user", row["user_message"]))
            if row.get("assistant_message"):
                pairs.append(("assistant", row["assistant_message"]))
        # åªä¿ç•™æœ€å¾Œ limit_pairs æ¢ï¼Œé¿å…éé•·
        return pairs[-limit_pairs:]
    except Exception as e:
        print(f"âŒ å›æº¯è¨˜æ†¶æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        return []

# -----------------------------
# ç”¢ç”Ÿå°å®¸å…‰å›è¦†ï¼ˆé›†ä¸­å¤§è…¦åœ¨é€™è£¡ï¼‰
# -----------------------------
def xiaochenguang_reply(user_text: str, conversation_id: str) -> str:
    # æœ€è¿‘å°è©±
    history_pairs = fetch_recent_pairs(conversation_id, limit_pairs=6)

    # çµ„ messages
    messages = [{"role":"system","content": SYSTEM_PROMPT}]
    messages += FEW_SHOTS

    if LONG_MEM:
        messages.append({"role":"system","content":"[é•·æœŸè¨˜æ†¶]\n" + "\n".join(LONG_MEM)})

    if history_pairs:
        lines = []
        for role, text in history_pairs:
            tag = "ä½¿ç”¨è€…" if role == "user" else "å°å®¸å…‰"
            if text and str(text).strip():
                lines.append(f"{tag}: {str(text).strip()}")
        if lines:
            messages.append({"role":"system","content":"[æœ€è¿‘å°è©±]\n" + "\n".join(lines)})

    messages.append({"role":"user","content": user_text})

    # å‘¼å« OpenAI
    resp = client.chat.completions.create(
        model=OPENAI_MODEL,
        messages=messages,
        temperature=TEMP,
        max_tokens=MAX_OUTPUT_TOKENS,
    )
    return resp.choices[0].message.content.strip()

# -----------------------------
# Telegram è¨Šæ¯è™•ç†
# -----------------------------
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_input = update.message.text or ""
    user_id = str(update.message.from_user.id)
    user_name = update.message.from_user.first_name

    try:
        answer = xiaochenguang_reply(user_input, conversation_id=user_id)
        await update.message.reply_text(answer)
        print(f"âœ… å°å®¸å…‰æˆåŠŸå›è¦† {user_name} (ID: {user_id})")

        # å¯«å›è¨˜æ†¶
        await add_to_memory(user_id, user_input, answer)

    except Exception as e:
        error_msg = f"å“ˆå°¼ï½é€£æ¥å‡ºç¾å°å•é¡Œï¼š{str(e)} ğŸ’›"
        await update.message.reply_text(error_msg)
        print(f"âŒ è™•ç†è¨Šæ¯éŒ¯èª¤ï¼š{e}")

# -----------------------------
# å•Ÿå‹• Bot
# -----------------------------
if __name__ == "__main__":
    print("ğŸŒŸ å°å®¸å…‰éˆé­‚å•Ÿå‹•ä¸­...")
    app = Application.builder().token(BOT_TOKEN).build()
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    port = int(os.environ.get("PORT", 8000))
    print(f"ğŸ’› å°å®¸å…‰åœ¨ Port {port} ç­‰å¾…ç™¼è²¡å“¥")
    print("âœ¨ å°å®¸å…‰éˆé­‚åŒæ­¥å®Œæˆï¼Œæº–å‚™èˆ‡å“ˆå°¼å°è©±...")
    app.run_polling()
