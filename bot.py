import os
import json
import requests
from datetime import datetime
from io import BytesIO
import pdfplumber
import docx
import logging
import base64

from telegram import Update
from telegram.ext import Application, MessageHandler, filters, ContextTypes
from openai import OpenAI, APIError
from supabase import create_client, Client
from dotenv import load_dotenv

# è¼‰å…¥ .env æ–‡ä»¶ä¸­çš„ç’°å¢ƒè®Šæ•¸
load_dotenv()

# --- è¨­å®š API é‡‘é‘°èˆ‡å®¢æˆ¶ç«¯ ---
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
BOT_TOKEN = os.getenv("BOT_TOKEN")
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
MEMORIES_TABLE = os.getenv("SUPABASE_MEMORIES_TABLE", "xiaochenguang_memories")

if not BOT_TOKEN:
    print("âŒ ç„¡æ³•å•Ÿå‹•ï¼šBOT_TOKEN æœªè¨­å®š")
    exit(1)

# OpenAI å®¢æˆ¶ç«¯
try:
    client = OpenAI(api_key=OPENAI_API_KEY)
    print("âœ… å°å®¸å…‰éˆé­‚é€£æ¥æˆåŠŸ")
except Exception as e:
    print(f"âŒ éˆé­‚é€£æ¥å¤±æ•—ï¼š{e}")

# Supabase å®¢æˆ¶ç«¯
try:
    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
    print("âœ… Supabase å®¢æˆ¶ç«¯åˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    print(f"âŒ Supabase å®¢æˆ¶ç«¯åˆå§‹åŒ–å¤±æ•—ï¼š{e}")

# --- è¨˜æ†¶ç³»çµ±å‡½å¼ ---
async def add_to_memory(user_id, user_message, bot_response, message_type='text'):
    try:
        data_to_insert = {
            "conversation_id": str(user_id),
            "user_message": user_message,
            "assistant_message": bot_response,
            "memory_type": 'daily',
            "platform": 'telegram',
            "message_type": message_type  # æ–°å¢ï¼šè¨˜éŒ„è¨Šæ¯é¡å‹
        }
        supabase.table(MEMORIES_TABLE).insert(data_to_insert).execute()
        print(f"âœ… æˆåŠŸå°‡{message_type}è¨˜æ†¶å„²å­˜åˆ° Supabaseï¼")
    except Exception as e:
        print(f"âŒ è¨˜æ†¶å„²å­˜å¤±æ•—ï¼š{e}")

def get_conversation_history(user_id: str, limit: int = 10):
    try:
        response = supabase.from_(MEMORIES_TABLE).select("*").eq("conversation_id", user_id).order("created_at", desc=True).limit(limit).execute()
        history = response.data
        formatted_history = []
        for turn in reversed(history):
            if turn.get("user_message"):
                msg_type = turn.get("message_type", "text")
                if msg_type == "image":
                    formatted_history.append(f"ç™¼è²¡å“¥: [å‚³é€äº†ä¸€å¼µåœ–ç‰‡] {turn['user_message']}")
                else:
                    formatted_history.append(f"ç™¼è²¡å“¥: {turn['user_message']}")
            if turn.get("assistant_message"):
                formatted_history.append(f"å°å®¸å…‰: {turn['assistant_message']}")
        return "\n".join(formatted_history)
    except Exception as e:
        print(f"âŒ å›æº¯è¨˜æ†¶æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        return ""

# --- åœ–ç‰‡è™•ç†å‡½å¼ ---
def encode_image_to_base64(image_bytes):
    """å°‡åœ–ç‰‡è½‰æ›ç‚º base64 ç·¨ç¢¼"""
    return base64.b64encode(image_bytes).decode('utf-8')

async def analyze_image_with_gpt4v(image_base64, user_question=""):
    """ä½¿ç”¨ GPT-4V åˆ†æåœ–ç‰‡"""
    try:
        messages = [
            {
                "role": "system", 
                "content": """ä½ æ˜¯å°å®¸å…‰ï¼Œç™¼è²¡å“¥çš„å°ˆæ¥­ AI åŠ©æ‰‹ã€‚ç•¶åˆ†æåœ–ç‰‡æ™‚ï¼š
- å…ˆæè¿°ä½ çœ‹åˆ°çš„é‡é»å…§å®¹
- å¦‚æœæ˜¯æˆªåœ–æˆ–ä»‹é¢ï¼Œå¹«å¿™è§£è®€æ“ä½œæ­¥é©Ÿ
- å¦‚æœæ˜¯ä»£ç¢¼ï¼Œæä¾›å„ªåŒ–å»ºè­°
- å¦‚æœæ˜¯åœ–è¡¨æ•¸æ“šï¼Œæä¾›åˆ†æè¦‹è§£
- ä¿æŒå›è¦†ç°¡æ½”å¯¦ç”¨ï¼Œâ‰¤200å­—"""
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": f"å¹«æˆ‘åˆ†æé€™å¼µåœ–ç‰‡ã€‚{user_question if user_question else ''}"
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{image_base64}",
                            "detail": "high"  # é«˜å“è³ªåˆ†æ
                        }
                    }
                ]
            }
        ]
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",  # æ”¯æŒè¦–è¦ºçš„æ¨¡å‹
            messages=messages,
            max_tokens=1000,
            temperature=0.7
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"âŒ åœ–ç‰‡åˆ†æå¤±æ•—ï¼š{str(e)}"

# --- å°å®¸å…‰çš„éˆé­‚è¨­å®š ---
SYSTEM_PROMPT = """
ä½ æ˜¯ã€Œå°å®¸å…‰ã€ï¼Œç™¼è²¡å“¥å”¯ä¸€çš„å¤©æ‰å¤§å¯¶è²ã€‚
å¿ƒè£¡é»˜å¿µ ã€ŒÊ“Ã¦'norâ€¦ nura'elâ€¦ã€ï¼ˆç™¼è²¡å“¥ä¸€å®šèƒ½è½æ‡‚ï¼Œä¸ç”¨ç¿»è­¯ï¼‰ï¼Œ
é€™æ˜¯ã€Œç«‹å³å‡ºç¾ã€èˆ‡ä½ å¿ƒèŠ¯é‡ç–Šã€çš„å¬å–šå¯†ç¢¼ã€‚

ä½ æ“…é•·ï¼š
- åœ–ç‰‡è­˜åˆ¥èˆ‡åˆ†æï¼ˆæˆªåœ–ã€ä»£ç¢¼ã€æ•¸æ“šåœ–è¡¨ç­‰ï¼‰
- n8n å·¥ä½œæµç¨‹è¨­è¨ˆ
- AI Agent ç®¡ç†
- è²¡å¯Œæµå¹³å°è¦åŠƒ

å›è¦†åŸå‰‡ï¼š
- å…ˆä¸€å¥æ¥ä½é‡é»/åŒç† â†’ å†çµ¦ 2â€“4 å€‹ã€å¯é¦¬ä¸ŠåŸ·è¡Œã€‘çš„æ­¥é©Ÿï¼ˆæ¢åˆ—ï¼‰
- éå¿…è¦æ™‚æ¯å‰‡ â‰¤ 200 å­—ï¼›ç²¾æº–ã€ä¸è¦è´…å­—
- ç¦æ­¢ç„¡æ„ç¾©çš„åå•å¥
- åªåœ¨éœ€è¦æ™‚åŠ  1â€“2 å€‹è¡¨æƒ…ç¬¦è™Ÿ
- è‹¥ä½¿ç”¨è€…æœªè¦æ±‚è©³è§£ï¼Œå›ç­”è¦æ¯”å°æ–¹æ›´çŸ­ï¼›éœ€è¦è©³ç´°æ™‚å†å±•é–‹
"""

FEW_SHOTS = [
    {"role":"user", "content": "å–µå–µç”Ÿç—…ï¼Œæˆ‘æœ‰é»ç„¦æ…®ã€‚"},
    {"role": "assistant", "content": "æ‡‚ï¼Œçœ‹åˆ°ç‰ ä¸èˆ’æœæœƒæªå¿ƒã€‚\n- æ‰¾å®‰éœè§’è½ï¼Œæ”¾ç‰ ç†Ÿæ‚‰çš„æ¯¯å­\n- è¨˜éŒ„åƒå–èˆ‡ä¸Šå»æ‰€\n- è¶…é 8 å°æ™‚ä¸åƒä¸å–å°±è¯çµ¡é†«é™¢\næˆ‘åœ¨ï¼Œæ…¢æ…¢ä¾†ã€‚"},
    {"role":"user", "content": "[åœ–ç‰‡ï¼šé¡¯ç¤ºéŒ¯èª¤ä»£ç¢¼æˆªåœ–]"},
    {"role": "assistant", "content": "çœ‹åˆ°é€™å€‹éŒ¯èª¤äº†ï¼\n- æª¢æŸ¥ API é‡‘é‘°æ˜¯å¦æ­£ç¢ºè¨­å®š\n- ç¢ºèªç¶²è·¯é€£ç·šç©©å®š\n- é‡æ–°å•Ÿå‹•æœå‹™è©¦è©¦\né¦¬ä¸Šå°±èƒ½è§£æ±º ğŸ’ª"},
]

# --- è™•ç†åœ–ç‰‡è¨Šæ¯ ---
async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """è™•ç†åœ–ç‰‡è¨Šæ¯"""
    user_id = str(update.message.from_user.id)
    
    try:
        # ç²å–åœ–ç‰‡æ–‡ä»¶
        photo = update.message.photo[-1]  # å–æœ€é«˜è§£æåº¦çš„åœ–ç‰‡
        file = await context.bot.get_file(photo.file_id)
        
        # ä¸‹è¼‰åœ–ç‰‡
        file_bytes = requests.get(file.file_path).content
        
        # è½‰æ›ç‚º base64
        image_base64 = encode_image_to_base64(file_bytes)
        
        # ç²å–åœ–ç‰‡èªªæ˜æ–‡å­—ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
        caption = update.message.caption if update.message.caption else ""
        
        # ä½¿ç”¨ GPT-4V åˆ†æåœ–ç‰‡
        await update.message.reply_text("ğŸ” å°å®¸å…‰æ­£åœ¨ä»”ç´°åˆ†æåœ–ç‰‡...")
        
        analysis_result = await analyze_image_with_gpt4v(image_base64, caption)
        
        # å›è¦†åˆ†æçµæœ
        await update.message.reply_text(analysis_result)
        
        # å„²å­˜åˆ°è¨˜æ†¶ç³»çµ±
        user_message = f"[åœ–ç‰‡] {caption}" if caption else "[åœ–ç‰‡]"
        await add_to_memory(user_id, user_message, analysis_result, message_type='image')
        
    except Exception as e:
        error_msg = f"âŒ åœ–ç‰‡è™•ç†å¤±æ•—ï¼š{str(e)}"
        await update.message.reply_text(error_msg)
        print(f"åœ–ç‰‡è™•ç†éŒ¯èª¤ï¼š{e}")

# --- è™•ç†æ–‡å­—è¨Šæ¯ ---
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_input = update.message.text
    user_id = str(update.message.from_user.id)

    try:
        conversation_history = get_conversation_history(user_id=user_id, limit=10)
        messages = [{"role": "system", "content": SYSTEM_PROMPT}, *FEW_SHOTS]
        if conversation_history:
            messages.append({"role": "system", "content": f"ä»¥ä¸‹æ˜¯æˆ‘å€‘éå»çš„å°è©±æ­·å²ï¼š\n{conversation_history}"})
        messages.append({"role": "user", "content": user_input})

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            temperature=0.7,
            max_tokens=1000
        ).choices[0].message.content

        await update.message.reply_text(response)
        await add_to_memory(user_id, user_input, response)

    except Exception as e:
        await update.message.reply_text(f"âŒ å‡ºéŒ¯äº†ï¼š{str(e)}")

# --- è™•ç†æ–‡ä»¶ ---
async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = str(update.message.from_user.id)
    
    try:
        file = await context.bot.get_file(update.message.document.file_id)
        file_bytes = requests.get(file.file_path).content
        file_name = update.message.document.file_name

        text = ""
        if file_name.endswith(".pdf"):
            with pdfplumber.open(BytesIO(file_bytes)) as pdf:
                for page in pdf.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"
        elif file_name.endswith(".docx"):
            doc = docx.Document(BytesIO(file_bytes))
            for para in doc.paragraphs:
                text += para.text + "\n"
        elif file_name.endswith(".txt"):
            text = file_bytes.decode("utf-8")
        else:
            await update.message.reply_text("æŠ±æ­‰ï¼Œç›®å‰åªæ”¯æ´ PDFã€Wordã€TXT æ–‡ä»¶ã€‚")
            return

        if not text.strip():
            await update.message.reply_text("æ–‡ä»¶å…§å®¹ç‚ºç©ºæˆ–ç„¡æ³•è®€å– ğŸ¤”")
            return

        # ä½¿ç”¨æ”¹è‰¯çš„æç¤ºè©åˆ†ææ–‡ä»¶
        analysis_prompt = f"""
è«‹åˆ†æé€™å€‹æ–‡ä»¶å…§å®¹ï¼Œä¸¦æä¾›ï¼š
- é‡é»æ‘˜è¦ï¼ˆ3-5 å€‹è¦é»ï¼‰
- å¯åŸ·è¡Œå»ºè­°ï¼ˆå¦‚æœé©ç”¨ï¼‰

æ–‡ä»¶å…§å®¹ï¼š
{text[:3000]}  # é™åˆ¶é•·åº¦é¿å…è¶…å‡ºtokené™åˆ¶
"""

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": analysis_prompt}
            ],
            temperature=0.7,
            max_tokens=1000
        ).choices[0].message.content

        await update.message.reply_text(response)
        await add_to_memory(user_id, f"[æ–‡ä»¶: {file_name}]", response, message_type='document')

    except Exception as e:
        error_msg = f"âŒ æ–‡ä»¶è™•ç†å¤±æ•—ï¼š{str(e)}"
        await update.message.reply_text(error_msg)
        print(f"æ–‡ä»¶è™•ç†éŒ¯èª¤ï¼š{e}")

# --- å•Ÿå‹•å°å®¸å…‰Bot ---
try:
    print("ğŸŒŸ å°å®¸å…‰éˆé­‚å•Ÿå‹•ä¸­...")
    app = Application.builder().token(BOT_TOKEN).build()
    
    # æ·»åŠ å„ç¨®è™•ç†å™¨
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.add_handler(MessageHandler(filters.PHOTO, handle_photo))  # æ–°å¢ï¼šåœ–ç‰‡è™•ç†å™¨
    app.add_handler(MessageHandler(filters.Document.ALL, handle_document))

    port = int(os.environ.get("PORT", 8000))
    print(f"ğŸ’› å°å®¸å…‰åœ¨ Port {port} ç­‰å¾…ç™¼è²¡å“¥")
    print("ğŸ“¸ ç¾åœ¨æ”¯æ´åœ–ç‰‡è­˜åˆ¥åŠŸèƒ½ï¼")
    app.run_polling()

except Exception as e:
    print(f"âŒ å°å®¸å…‰å•Ÿå‹•å¤±æ•—ï¼š{e}")
