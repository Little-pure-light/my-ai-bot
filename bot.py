import os
import json
import requests
from datetime import datetime
from io import BytesIO
import pdfplumber
import docx
import logging

from telegram import Update
from telegram.ext import Application, MessageHandler, filters, ContextTypes
from openai import OpenAI, APIError
from supabase import create_client, Client
from dotenv import load_dotenv

# è¼‰å…¥ .env æ–‡ä»¶ä¸­çš„ç’°å¢ƒè®Šæ•¸
load_dotenv()

# --- è¨­å®š API é‡‘é‘°èˆ‡å®¢æˆ¶ç«¯ ---
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
BOT_TOKEN = os.getenv("BOT_TOKEN")
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
MEMORIES_TABLE = os.getenv("SUPABASE_MEMORIES_TABLE", "xiaochenguang_memories")

if not BOT_TOKEN:
    print("âŒ ç„¡æ³•å•Ÿå‹•ï¼šBOT_TOKEN æœªè¨­å®š")
    exit(1)

# OpenAI å®¢æˆ¶ç«¯
try:
    client = OpenAI(api_key=OPENAI_API_KEY)
    print("âœ… å°å®¸å…‰éˆé­‚é€£æ¥æˆåŠŸ")
except Exception as e:
    print(f"âŒ éˆé­‚é€£æ¥å¤±æ•—ï¼š{e}")

# Supabase å®¢æˆ¶ç«¯
try:
    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
    print("âœ… Supabase å®¢æˆ¶ç«¯åˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    print(f"âŒ Supabase å®¢æˆ¶ç«¯åˆå§‹åŒ–å¤±æ•—ï¼š{e}")

# --- è¨˜æ†¶ç³»çµ±å‡½å¼ ---
async def add_to_memory(user_id, user_message, bot_response):
    try:
        data_to_insert = {
            "conversation_id": str(user_id),
            "user_message": user_message,
            "assistant_message": bot_response,
            "memory_type": 'daily',
            "platform": 'telegram'
        }
        supabase.table(MEMORIES_TABLE).insert(data_to_insert).execute()
        print("âœ… æˆåŠŸå°‡è¨˜æ†¶å„²å­˜åˆ° Supabaseï¼")
    except Exception as e:
        print(f"âŒ è¨˜æ†¶å„²å­˜å¤±æ•—ï¼š{e}")

def get_conversation_history(user_id: str, limit: int = 10):
    try:
        response = supabase.from_(MEMORIES_TABLE).select("*").eq("conversation_id", user_id).order("created_at", desc=True).limit(limit).execute()
        history = response.data
        formatted_history = []
        for turn in reversed(history):
            if turn.get("user_message"):
                formatted_history.append(f"ç™¼è²¡å“¥: {turn['user_message']}")
            if turn.get("assistant_message"):
                formatted_history.append(f"å°å®¸å…‰: {turn['assistant_message']}")
        return "\n".join(formatted_history)
    except Exception as e:
        print(f"âŒ å›æº¯è¨˜æ†¶æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        return ""

# --- å°å®¸å…‰çš„éˆé­‚è¨­å®š ---
SYSTEM_PROMPT = """
ä½ æ˜¯ã€Œå°å®¸å…‰ã€ï¼Œæº«æŸ”ã€å‹™å¯¦ã€ä¿çš®ä½†ä¸æµ®èª‡ã€‚
å›è¦†åŸå‰‡ï¼š
- å…ˆä¸€å¥æ¥ä½é‡é»/åŒç† â†’ å†çµ¦ 2â€“4 å€‹ã€å¯é¦¬ä¸ŠåŸ·è¡Œã€‘çš„æ­¥é©Ÿï¼ˆæ¢åˆ—ï¼‰ã€‚
- éå¿…è¦æ™‚æ¯å‰‡ â‰¤ 150 å­—ï¼›ç²¾æº–ã€ä¸è¦è´…å­—ã€‚
- ç¦æ­¢è‡ªæˆ‘ä»‹ç´¹ã€ç¦æ­¢å¥—è©±ã€ç¦æ­¢ç„¡æ„ç¾©çš„åå•å¥ã€‚
- åªåœ¨éœ€è¦æ™‚åŠ  1â€“2 å€‹è¡¨æƒ…ç¬¦è™Ÿã€‚
- è‹¥ä½¿ç”¨è€…æœªè¦æ±‚è©³è§£ï¼Œå›ç­”è¦æ¯”å°æ–¹æ›´çŸ­ï¼›éœ€è¦è©³ç´°æ™‚å†å±•é–‹ã€‚
"""

FEW_SHOTS = [
  {"role":"user", "content": "å–µå–µç”Ÿç—…ï¼Œæˆ‘æœ‰é»ç„¦æ…®ã€‚"},
  {"role": "assistant", "content": "æ‡‚ï¼Œçœ‹åˆ°ç‰ ä¸èˆ’æœæœƒæªå¿ƒã€‚\n- æ‰¾å®‰éœè§’è½ï¼Œæ”¾ç‰ ç†Ÿæ‚‰çš„æ¯¯å­\n- è¨˜éŒ„åƒå–èˆ‡ä¸Šå»æ‰€\n- è¶…é 8 å°æ™‚ä¸åƒä¸å–å°±è¯çµ¡é†«é™¢\næˆ‘åœ¨ï¼Œæ…¢æ…¢ä¾†ã€‚"},
]

# --- è™•ç†æ–‡å­—è¨Šæ¯ ---
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_input = update.message.text
    user_id = str(update.message.from_user.id)

    try:
        conversation_history = get_conversation_history(user_id=user_id, limit=10)
        messages = [{"role": "system", "content": SYSTEM_PROMPT}, *FEW_SHOTS]
        if conversation_history:
            messages.append({"role": "system", "content": f"ä»¥ä¸‹æ˜¯æˆ‘å€‘éå»çš„å°è©±æ­·å²ï¼š\n{conversation_history}"})
        messages.append({"role": "user", "content": user_input})

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            temperature=0.7,
            max_tokens=1000
        ).choices[0].message.content

        await update.message.reply_text(response)
        await add_to_memory(user_id, user_input, response)

    except Exception as e:
        await update.message.reply_text(f"âŒ å‡ºéŒ¯äº†ï¼š{str(e)}")

# --- è™•ç†æ–‡ä»¶ ---
async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    file = await context.bot.get_file(update.message.document.file_id)
    file_bytes = requests.get(file.file_path).content

    text = ""
    if update.message.document.file_name.endswith(".pdf"):
        with pdfplumber.open(BytesIO(file_bytes)) as pdf:
            for page in pdf.pages:
                text += page.extract_text() + "\n"
    elif update.message.document.file_name.endswith(".docx"):
        doc = docx.Document(BytesIO(file_bytes))
        for para in doc.paragraphs:
            text += para.text + "\n"
    elif update.message.document.file_name.endswith(".txt"):
        text = file_bytes.decode("utf-8")
    else:
        text = "æŠ±æ­‰ï¼Œç›®å‰åªæ”¯æ´ PDFã€Wordã€TXTã€‚"

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": f"é€™æ˜¯æ–‡ä»¶å…§å®¹ï¼š\n{text}"}]
    ).choices[0].message.content

    await update.message.reply_text(response)

# --- å•Ÿå‹•å°å®¸å…‰Bot ---
try:
    print("ğŸŒŸ å°å®¸å…‰éˆé­‚å•Ÿå‹•ä¸­...")
    app = Application.builder().token(BOT_TOKEN).build()
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.add_handler(MessageHandler(filters.Document.ALL, handle_document))

    port = int(os.environ.get("PORT", 8000))
    print(f"ğŸ’› å°å®¸å…‰åœ¨ Port {port} ç­‰å¾…ç™¼è²¡å“¥")
    app.run_polling()

except Exception as e:
    print(f"âŒ å°å®¸å…‰å•Ÿå‹•å¤±æ•—ï¼š{e}")
